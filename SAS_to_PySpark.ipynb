{"cells":[{"cell_type":"markdown","source":["# Let's use the famous Titanic dataset and perform the following operations using SAS:\n\n1. Load the dataset from a CSV file\n2. Explore and manipulate the dataset\n3. Apply machine learning algorithm to predict survival using logistic regression\n4. Aggregate the data to get summary statistics\n5. Select and drop columns as needed\n6. Perform statistical and mathematical calculations\n\nHere's the SAS code:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"438c1632-7b17-4bce-bd70-e226a81d15f3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\"\"\"\n/* Load the Titanic dataset from a CSV file */\nproc import datafile='titanic.csv'\n            out=titanic\n            dbms=csv replace;\n            getnames=yes;\nrun;\n\n/* Explore the dataset */\nproc contents data=titanic;\nrun;\n\nproc print data=titanic(obs=5);\nrun;\n\n/* Manipulate the dataset */\n/* Create a new column for family size */\ndata titanic;\n    set titanic;\n    family_size = sibsp + parch + 1;\nrun;\n\n/* Apply machine learning algorithm */\n/* Predict survival using logistic regression */\n/* Split data into training and testing sets */\ndata titanic_train titanic_test;\n    set titanic;\n    if mod(_n_, 5) = 0 then output titanic_test;\n    else output titanic_train;\nrun;\n\n/* Fit a logistic regression model */\nproc logistic data=titanic_train;\n    model survived = sex age fare class family_size / selection=stepwise;\n    score data=titanic_test out=titanic_predicted;\nrun;\n\n/* Aggregate the data */\n/* Get summary statistics */\nproc means data=titanic mean median min max n;\n    var age fare family_size;\n    class survived sex;\nrun;\n\n/* Select and drop columns */\n/* Select columns of interest */\nproc sql;\n    create table titanic_selected as\n    select sex, age, fare, survived\n    from titanic;\nquit;\n\n/* Drop columns */\ndata titanic_dropped;\n    set titanic;\n    drop name cabin;\nrun;\n\n/* Perform statistical and mathematical calculations */\n/* Calculate the correlation matrix */\nproc corr data=titanic;\n    var age fare family_size;\nrun;\n\n/* Calculate the mean and standard deviation */\ndata titanic_stats;\n    set titanic;\n    mean_age = mean(age);\n    std_dev_fare = std(fare);\nrun;\n\"\"\"\n\n\nprint(\"This is my SAS code\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"71cc20a1-6ade-4ddd-a17b-6557cd4317bf","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["This is my SAS code\n"]}],"execution_count":0},{"cell_type":"markdown","source":["# SAS to PySpark Conversion"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"02843991-74d5-4f9b-9e8b-304b9b4632c5","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# Python to PySpark Conversion"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"172d9fdf-a48d-4561-b479-57b31281efa5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Load the Titanic dataset from a CSV file:\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"Titanic\").getOrCreate()\ntitanic = spark.read.csv(\"dbfs:/FileStore/shared_uploads/purvajainpj123@gmail.com/titanic.csv\", header=True, inferSchema=True)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eb0e5f08-52a2-437a-9cb8-62ea68d3caae","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Explore the dataset:\ntitanic.printSchema()\ntitanic.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"881fbee6-6e3d-431e-8bc8-db8992e4404e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- Survived: integer (nullable = true)\n |-- Pclass: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Sex: string (nullable = true)\n |-- Age: double (nullable = true)\n |-- Siblings/Spouses Aboard: integer (nullable = true)\n |-- Parents/Children Aboard: integer (nullable = true)\n |-- Fare: double (nullable = true)\n\n+--------+------+--------------------+------+----+-----------------------+-----------------------+-------+\n|Survived|Pclass|                Name|   Sex| Age|Siblings/Spouses Aboard|Parents/Children Aboard|   Fare|\n+--------+------+--------------------+------+----+-----------------------+-----------------------+-------+\n|       0|     3|Mr. Owen Harris B...|  male|22.0|                      1|                      0|   7.25|\n|       1|     1|Mrs. John Bradley...|female|38.0|                      1|                      0|71.2833|\n|       1|     3|Miss. Laina Heikk...|female|26.0|                      0|                      0|  7.925|\n|       1|     1|Mrs. Jacques Heat...|female|35.0|                      1|                      0|   53.1|\n|       0|     3|Mr. William Henry...|  male|35.0|                      0|                      0|   8.05|\n+--------+------+--------------------+------+----+-----------------------+-----------------------+-------+\nonly showing top 5 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Manipulate the dataset:\nfrom pyspark.sql.functions import col\n\ntitanic = titanic.withColumn(\"family_size\", col(\"Siblings/Spouses Aboard\") + col(\"Parents/Children Aboard\") + 1)\n\ntitanic.show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e8562030-dcea-4a7e-b47d-e5ec197127b4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------+------+--------------------+------+----+-----------------------+-----------------------+-------+-----------+\n|Survived|Pclass|                Name|   Sex| Age|Siblings/Spouses Aboard|Parents/Children Aboard|   Fare|family_size|\n+--------+------+--------------------+------+----+-----------------------+-----------------------+-------+-----------+\n|       0|     3|Mr. Owen Harris B...|  male|22.0|                      1|                      0|   7.25|          2|\n|       1|     1|Mrs. John Bradley...|female|38.0|                      1|                      0|71.2833|          2|\n|       1|     3|Miss. Laina Heikk...|female|26.0|                      0|                      0|  7.925|          1|\n|       1|     1|Mrs. Jacques Heat...|female|35.0|                      1|                      0|   53.1|          2|\n|       0|     3|Mr. William Henry...|  male|35.0|                      0|                      0|   8.05|          1|\n+--------+------+--------------------+------+----+-----------------------+-----------------------+-------+-----------+\nonly showing top 5 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.types import DoubleType\n\n# Split data into training and testing sets\ntitanic_train, titanic_test = titanic.randomSplit([0.8, 0.2], seed=42)\n\n# Convert categorical variable to numerical variable\nsex_indexer = StringIndexer(inputCol='Sex', outputCol='SexIndex')\nsex_encoder = OneHotEncoder(inputCols=['SexIndex'], outputCols=['SexVec'])\nassembler = VectorAssembler(inputCols=['SexVec', 'Age', 'Fare', 'Pclass', 'family_size'], outputCol='features')\ntitanic_train = sex_indexer.fit(titanic_train).transform(titanic_train)\ntitanic_train = sex_encoder.fit(titanic_train).transform(titanic_train)\ntitanic_train = assembler.transform(titanic_train)\ntitanic_test = sex_indexer.fit(titanic_test).transform(titanic_test)\ntitanic_test = sex_encoder.fit(titanic_test).transform(titanic_test)\ntitanic_test = assembler.transform(titanic_test)\n\n# Fit a logistic regression model\nlr = LogisticRegression(featuresCol='features', labelCol='Survived', maxIter=10)\nmodel = lr.fit(titanic_train)\n\n# Make predictions on the test set\npredictions = model.transform(titanic_test)\n\n# Evaluate the model's accuracy\nevaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='Survived')\naccuracy = evaluator.evaluate(predictions)\nerror = 1 - accuracy\nprint('Accuracy:', accuracy)\nprint('Error:', error)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bdaf75b6-13ba-433f-8b29-aa941bfe414d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Accuracy: 0.8620481927710847\nError: 0.1379518072289153\n"]}],"execution_count":0},{"cell_type":"code","source":["# Aggregate the data\n# Get summary statistics\nfrom pyspark.sql.functions import mean, median, min, max, count\n\nsummary = titanic.groupby(['Survived', 'Sex']).agg(\n    mean('Age').alias('mean_age'),\n    median('Age').alias('median_age'),\n    min('Age').alias('min_age'),\n    max('Age').alias('max_age'),\n    mean('Fare').alias('mean_fare'),\n    median('Fare').alias('median_fare'),\n    min('Fare').alias('min_fare'),\n    max('Fare').alias('max_fare'),\n    mean('family_size').alias('mean_family_size'),\n    median('family_size').alias('median_family_size'),\n    min('family_size').alias('min_family_size'),\n    max('family_size').alias('max_family_size'),\n    count('*').alias('count')\n)\nsummary.limit(5).toPandas()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3bc0dcfa-2914-4e8b-bac0-5ca0f32280e1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Sex</th>\n      <th>mean_age</th>\n      <th>median_age</th>\n      <th>min_age</th>\n      <th>max_age</th>\n      <th>mean_fare</th>\n      <th>median_fare</th>\n      <th>min_fare</th>\n      <th>max_fare</th>\n      <th>mean_family_size</th>\n      <th>median_family_size</th>\n      <th>min_family_size</th>\n      <th>max_family_size</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>female</td>\n      <td>24.419753</td>\n      <td>22.0</td>\n      <td>2.00</td>\n      <td>62.0</td>\n      <td>23.024385</td>\n      <td>15.24580</td>\n      <td>6.750</td>\n      <td>151.5500</td>\n      <td>3.246914</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>male</td>\n      <td>27.428165</td>\n      <td>28.0</td>\n      <td>0.42</td>\n      <td>80.0</td>\n      <td>40.821484</td>\n      <td>26.28750</td>\n      <td>0.000</td>\n      <td>512.3292</td>\n      <td>1.743119</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>109</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>female</td>\n      <td>28.866953</td>\n      <td>28.0</td>\n      <td>0.75</td>\n      <td>63.0</td>\n      <td>51.938573</td>\n      <td>26.00000</td>\n      <td>7.225</td>\n      <td>512.3292</td>\n      <td>2.030043</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>233</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>male</td>\n      <td>31.136853</td>\n      <td>28.0</td>\n      <td>1.00</td>\n      <td>74.0</td>\n      <td>22.066170</td>\n      <td>9.49165</td>\n      <td>0.000</td>\n      <td>263.0000</td>\n      <td>1.653017</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>464</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Sex</th>\n      <th>mean_age</th>\n      <th>median_age</th>\n      <th>min_age</th>\n      <th>max_age</th>\n      <th>mean_fare</th>\n      <th>median_fare</th>\n      <th>min_fare</th>\n      <th>max_fare</th>\n      <th>mean_family_size</th>\n      <th>median_family_size</th>\n      <th>min_family_size</th>\n      <th>max_family_size</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>female</td>\n      <td>24.419753</td>\n      <td>22.0</td>\n      <td>2.00</td>\n      <td>62.0</td>\n      <td>23.024385</td>\n      <td>15.24580</td>\n      <td>6.750</td>\n      <td>151.5500</td>\n      <td>3.246914</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>male</td>\n      <td>27.428165</td>\n      <td>28.0</td>\n      <td>0.42</td>\n      <td>80.0</td>\n      <td>40.821484</td>\n      <td>26.28750</td>\n      <td>0.000</td>\n      <td>512.3292</td>\n      <td>1.743119</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>109</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>female</td>\n      <td>28.866953</td>\n      <td>28.0</td>\n      <td>0.75</td>\n      <td>63.0</td>\n      <td>51.938573</td>\n      <td>26.00000</td>\n      <td>7.225</td>\n      <td>512.3292</td>\n      <td>2.030043</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>233</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>male</td>\n      <td>31.136853</td>\n      <td>28.0</td>\n      <td>1.00</td>\n      <td>74.0</td>\n      <td>22.066170</td>\n      <td>9.49165</td>\n      <td>0.000</td>\n      <td>263.0000</td>\n      <td>1.653017</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>464</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Select and drop columns\n# Select columns of interest\nfrom pyspark.sql.functions import col\n\ntitanic_selected = titanic.select(col('Sex'), col('Age'), col('Fare'), col('Survived'))\ntitanic_selected.show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"34e6456c-7d4d-4faf-b3b7-b644f07b1063","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+----+-------+--------+\n|   Sex| Age|   Fare|Survived|\n+------+----+-------+--------+\n|  male|22.0|   7.25|       0|\n|female|38.0|71.2833|       1|\n|female|26.0|  7.925|       1|\n|female|35.0|   53.1|       1|\n|  male|35.0|   8.05|       0|\n+------+----+-------+--------+\nonly showing top 5 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Drop columns\ntitanic_dropped = titanic.drop('Name')\ntitanic_dropped.show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"80eb01e8-a24e-4453-824b-f1e2524ce595","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------+------+------+----+-----------------------+-----------------------+-------+-----------+\n|Survived|Pclass|   Sex| Age|Siblings/Spouses Aboard|Parents/Children Aboard|   Fare|family_size|\n+--------+------+------+----+-----------------------+-----------------------+-------+-----------+\n|       0|     3|  male|22.0|                      1|                      0|   7.25|          2|\n|       1|     1|female|38.0|                      1|                      0|71.2833|          2|\n|       1|     3|female|26.0|                      0|                      0|  7.925|          1|\n|       1|     1|female|35.0|                      1|                      0|   53.1|          2|\n|       0|     3|  male|35.0|                      0|                      0|   8.05|          1|\n+--------+------+------+----+-----------------------+-----------------------+-------+-----------+\nonly showing top 5 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import mean, stddev, lit\n\n# Calculate the correlation matrix\ncorr_matrix = titanic.select('Age', 'Fare', 'family_size').toPandas().corr()\nprint(corr_matrix)\n\n# Calculate the mean and standard deviation\ntitanic_stats = titanic.select('Age', 'Fare')\n\nmean_age = titanic_stats.select(mean('Age')).first()[0]\nstd_dev_fare = titanic_stats.select(stddev('Fare')).first()[0]\n\ntitanic_stats = titanic_stats.withColumn('mean_age', lit(mean_age))\ntitanic_stats = titanic_stats.withColumn('std_dev_fare', lit(std_dev_fare))\n\ntitanic_stats.show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3aa62ac0-17d3-412c-8f4d-20881bdfe36b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["                  Age      Fare  family_size\nAge          1.000000  0.112329    -0.300297\nFare         0.112329  1.000000     0.216250\nfamily_size -0.300297  0.216250     1.000000\n+----+-------+------------------+-----------------+\n| Age|   Fare|          mean_age|     std_dev_fare|\n+----+-------+------------------+-----------------+\n|22.0|   7.25|29.471443066516347|49.78204040017391|\n|38.0|71.2833|29.471443066516347|49.78204040017391|\n|26.0|  7.925|29.471443066516347|49.78204040017391|\n|35.0|   53.1|29.471443066516347|49.78204040017391|\n|35.0|   8.05|29.471443066516347|49.78204040017391|\n+----+-------+------------------+-----------------+\nonly showing top 5 rows\n\n"]}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.10.6","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"SAS_to_PySpark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1213363716684154}},"nbformat":4,"nbformat_minor":0}
