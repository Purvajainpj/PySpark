{"cells":[{"cell_type":"markdown","source":["# Joining and Appending DataFrames in PySpark\n\nIn this notebook we will be reviewing the foundational concepts of joinings and appending dataframes as well as the necessary PySpark calls to accomplish these tasks. \n\nSo let's start!"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"961b9c94-0e56-4006-a610-aeb66472cd19","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# import findspark\n# findspark.init()\n\nimport pyspark # only run after findspark.init()\nfrom pyspark.sql import SparkSession\n# May take awhile locally\nspark = SparkSession.builder.appName(\"joins\").getOrCreate()\n\ncores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\nprint(\"You are working with\", cores, \"core(s)\")\nspark"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"31e49a47-51be-4777-ad98-98046f2224ce","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["You are working with 1 core(s)\n"]},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=3361741475360479#setting/sparkui/0320-103412-u70scn06/driver-2329180723244370067\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=3361741475360479#setting/sparkui/0320-103412-u70scn06/driver-2329180723244370067\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"markdown","source":["## Generate play data\n\nFirst some play data to help us grasp some concepts. Let's create a database that has two tables. \n\n**Key Terms**\n - **omnivore**: an animal which is able to consume both plants (like a herbivore) and meat (like a carnivore)\n - **herbivore**: any animal that eats only vegetation (i.e. that eats no meat)\n - **carnivore**: any animal that eats meat as the main part of its diet"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e49f7ea5-7612-462a-a4b7-92f1e7d78ae5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["valuesP = [('koala',1,'yes'),('caterpillar',2,'yes'),('deer',3,'yes'),('human',4,'yes')]\neats_plants = spark.createDataFrame(valuesP,['name','id','eats_plants'])\n\nvaluesM = [('shark',5,'yes'),('lion',6,'yes'),('tiger',7,'yes'),('human',4,'yes')]\neats_meat = spark.createDataFrame(valuesM,['name','id','eats_meat'])\n\n# print(\"Plant eaters (herbivores)\")\n# print(eats_plants.show())\n# print(\"Meat eaters (carnivores)\")\n# print(eats_meat.show())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6f485d60-f6cd-4a5e-9967-4e6f09326530","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Appends\n\nAppending \"appends\" two dataframes together that have the exact same variables. It is like stacking two or more blocks ON TOP of each other."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"80284cae-189e-4c38-b3ce-e7674557b205","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"391abd6c-6433-4f7b-b400-a1300a8b49fa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"},"removedWidgets":[],"addedWidgets":{},"executionCount":null,"metadata":{"kernelSessionId":"8d583190-a091dfd5c02606806085a42c"},"type":"mimeBundle","arguments":{}}},"output_type":"display_data","data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"}}],"execution_count":0},{"cell_type":"code","source":["# So first replicate table and call it new_df\nnew_df = eats_plants\n# Then append using the union function\n# this naming convention can be tricky to grasp for SQL enthusiasts \n# Where union just mean join\ndf_concat = eats_plants.union(new_df)\n# We will test to see if this worked by getting before and after row counts\nprint((\"eats_plants df Counts:\", eats_plants.count(), len(eats_plants.columns)))\nprint((\"df_concat Counts:\", df_concat.count(), len(df_concat.columns)))\nprint(eats_plants.show(5))\nprint(df_concat.show(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"205799c9-e987-4207-8657-31b87aa88b21","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["('eats_plants df Counts:', 4, 3)\n('df_concat Counts:', 8, 3)\n+-----------+---+-----------+\n|       name| id|eats_plants|\n+-----------+---+-----------+\n|      koala|  1|        yes|\n|caterpillar|  2|        yes|\n|       deer|  3|        yes|\n|      human|  4|        yes|\n+-----------+---+-----------+\n\nNone\n+-----------+---+-----------+\n|       name| id|eats_plants|\n+-----------+---+-----------+\n|      koala|  1|        yes|\n|caterpillar|  2|        yes|\n|       deer|  3|        yes|\n|      human|  4|        yes|\n|      koala|  1|        yes|\n+-----------+---+-----------+\nonly showing top 5 rows\n\nNone\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Inner Joins!\n\nInner joins get us ONLY the values that appear in BOTH tables we are joining."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8b09d1fb-eed1-42da-a3f4-3048ad044805","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["inner_join = eats_plants.join(eats_meat, [\"name\",\"id\"],\"inner\")\nprint(\"Inner Join Example\")\nprint(inner_join.show())\n# So this is the only name that appears in BOTH dataframes"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c0970741-7288-4539-bf8e-3458b038e89b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Inner Join Example\n+-----+---+-----------+---------+\n| name| id|eats_plants|eats_meat|\n+-----+---+-----------+---------+\n|human|  4|        yes|      yes|\n+-----+---+-----------+---------+\n\nNone\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Left Joins\n\nLeft joins get us the values that appear in the left table and nothing additional from the right table except for its columns. A quick quality check we could do would be to make sure that the human column has the value \"yes\" for both eats_plants and eats_meat columns."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"12d7e453-84d9-4ee8-b0bf-83ad785510cf","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["left_join = eats_plants.join(eats_meat, [\"name\",\"id\"], how='left') # Could also use 'left_outer'\nprint(\"Left Join Example\")\nprint(left_join.show())\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"099a4874-2bcc-40f4-94ad-43fb79aeb737","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Left Join Example\n+-----------+---+-----------+---------+\n|       name| id|eats_plants|eats_meat|\n+-----------+---+-----------+---------+\n|      koala|  1|        yes|     null|\n|caterpillar|  2|        yes|     null|\n|       deer|  3|        yes|     null|\n|      human|  4|        yes|      yes|\n+-----------+---+-----------+---------+\n\nNone\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Conditional Joins\n\nConditional joins have some additional logic that was not encompassed in the underlying join. For example, if we wanted to get all the values that appear in the left, **except** for those values that appear in BOTH tables, we could do this. Notice how human is left out now."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"32d09129-ce9d-4797-8f06-1d713f6ece51","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["conditional_join = eats_plants.join(eats_meat, [\"name\",\"id\"], how='left').filter(eats_meat.name.isNull())\nprint(\"Conditional Left Join\")\nprint(conditional_join.show())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f6eef3d2-87c2-4d89-9846-e98b329acb98","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Conditional Left Join\n+-----------+---+-----------+---------+\n|       name| id|eats_plants|eats_meat|\n+-----------+---+-----------+---------+\n|      koala|  1|        yes|     null|\n|caterpillar|  2|        yes|     null|\n|       deer|  3|        yes|     null|\n+-----------+---+-----------+---------+\n\nNone\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Right Join\n\nA right join gets us the values that appear in the right table but not in the left. It also brings it's columns over of course."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a567f4f7-4198-4c2f-8ac7-147be53a9829","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["right_join = eats_plants.join(eats_meat,  [\"name\",\"id\"],how='right') # Could also use 'right_outer'\nprint(\"Right Join\")\nprint(right_join.show())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0a152ed5-b6ef-4569-ada9-025626e189d6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Right Join\n+-----+---+-----------+---------+\n| name| id|eats_plants|eats_meat|\n+-----+---+-----------+---------+\n|shark|  5|       null|      yes|\n| lion|  6|       null|      yes|\n|tiger|  7|       null|      yes|\n|human|  4|        yes|      yes|\n+-----+---+-----------+---------+\n\nNone\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Full Outer Joins\n\nFull outer joins will get all values from both tables, but notice that if there is a column that is common in both tables (ie. id and name in this case) that the join will take the value of the left table (see human id is p4 and not m4)."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8c3323d2-2bf0-4160-8aa9-88686c0ede68","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["full_outer_join = eats_plants.join(eats_meat, [\"name\",\"id\"],how='full') # Could also use 'full_outer'\nprint(\"Full Outer Join\")\nprint(full_outer_join.show())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"baa3f6ea-3fb0-4cce-8a73-7fd1d9adc2ab","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Full Outer Join\n+-----------+---+-----------+---------+\n|       name| id|eats_plants|eats_meat|\n+-----------+---+-----------+---------+\n|caterpillar|  2|        yes|     null|\n|       deer|  3|        yes|     null|\n|      human|  4|        yes|      yes|\n|      koala|  1|        yes|     null|\n|       lion|  6|       null|      yes|\n|      shark|  5|       null|      yes|\n|      tiger|  7|       null|      yes|\n+-----------+---+-----------+---------+\n\nNone\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## With REAL data\n\nThinking about how to join our data in real life will not be as easy as the above. We need to consider multiple aspects as we join tables in real life and ALWAYS conduct sanity checks to make sure we did it correctly. Let's look at an example with real data.\n\n#### First, let's read in the datasets we will be working with\n\nHere is a neat function that will read in all the csv files from a directory (folder) in one shot and returns a separate dataframe for each dataset in the directory using the same naming convention. This is super useful if you have a large set of files and don't feel like writing a separate line for each dataset in the directory."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3d5eb9a6-a957-4d0c-8782-7067f786002c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["dbfs_path = \"/FileStore/shared_uploads/purvajainpj123@gmail.com\"\n\ndf_list = []\nfor filename in dbutils.fs.ls(dbfs_path):\n  if filename.name.endswith(\".csv\"):\n    df_name = filename.name.split(\".\")[0]\n    df = spark.read.csv(filename.path, header=True, inferSchema=True)\n    df_list.append(df_name)\n    globals()[df_name] = df\n\n# QA\nprint(\"Full list of dfs:\")\nprint(df_list)\n"],"metadata":{"scrolled":true,"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a86cc4c9-fa37-424c-9b84-7980c50b662f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Full list of dfs:\n['13_SMSSpamCollection', 'Hack_data-1', 'Hack_data-2', 'Hack_data', 'Musical_instruments_reviews', 'course_offerings', 'courses', 'customer_churn', 'grade_distributions', 'instructors', 'iris-1', 'iris', 'iris_dataset_new-1', 'iris_dataset_new', 'new_customers', 'nyc', 'rooms', 'schedules', 'sections', 'subject_memberships', 'subjects', 'teachings']\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## About this database\n\nThere are several tables that were read in above. This database will let us get a chance to practice our own custom joins and learn how the relationships between a real database work. Sometimes we don't know how they are related and we need to figure it out! \n\nFor this we will focus on the 4 datasets below and save the rest for the HW. Here is a look at some of the important variables we will be using to join our tables:\n\n - **course_offerings:** uuid, course_uuid, term_code, name\n - **instructors:** id, name\n - **sections:** uuid, course_offering_uuid,room_uuid, schedule_uuid\n - **teachings:** instructor_id, section_uuid\n \n **Source:** https://www.kaggle.com/Madgrades/uw-madison-courses\n \nLet's pretend that I am a student interested in seeing what courses are available. I suppose I would start by look at the course offerings table."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"86bf87f3-0742-4a5c-b4c0-ed68506c413d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# View the data\ncourse_offerings.limit(4).toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"46667ea8-fbb3-43b8-90fc-709de8348d58","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uuid</th>\n      <th>course_uuid</th>\n      <th>term_code</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>344b3ebe-da7e-314c-83ed-9425269695fd</td>\n      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n      <td>1092</td>\n      <td>Cooperative Education Prog</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f718e6cd-33f0-3c14-a9a6-834d9c3610a8</td>\n      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n      <td>1082</td>\n      <td>Cooperative Education Prog</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n      <td>1172</td>\n      <td>Cooperative Education Prog</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>075da420-5f49-3dd0-93df-13e3c152e1b1</td>\n      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n      <td>1114</td>\n      <td>Cooperative Education Prog</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uuid</th>\n      <th>course_uuid</th>\n      <th>term_code</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>344b3ebe-da7e-314c-83ed-9425269695fd</td>\n      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n      <td>1092</td>\n      <td>Cooperative Education Prog</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f718e6cd-33f0-3c14-a9a6-834d9c3610a8</td>\n      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n      <td>1082</td>\n      <td>Cooperative Education Prog</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n      <td>1172</td>\n      <td>Cooperative Education Prog</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>075da420-5f49-3dd0-93df-13e3c152e1b1</td>\n      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n      <td>1114</td>\n      <td>Cooperative Education Prog</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["This course offers table is great, but I also want to know who teaches each course because I want to check the reviews of the instructor before I take the course. Let's see if we can join this table with the instructors table that contains the name of the instructor."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1adca751-5f1d-4af2-bfe9-e6584295f1b6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["instructors.show(4,False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9342b8f4-e236-4b61-8cef-e539375f734a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+------------------+\n|id     |name              |\n+-------+------------------+\n|761703 |JOHN ARCHAMBAULT  |\n|3677061|STEPHANIE KANN    |\n|788586 |KATHY PREM        |\n|1600463|KRISTIN KLARKOWSKI|\n+-------+------------------+\nonly showing top 4 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["So this table only contains 2 columns (id and name) and doesn't have the uuid or course uuid to join on. So we will need to see how we can accomplish the join we need. It looks like from the tables we have, we would need to take the following steps to get the variables we need. \n\n - **course_offerings (CO):** uuid, course_uuid, term_code, name\n - **instructors (I):** id, name\n - **sections (S):** uuid, course_offering_uuid,room_uuid, schedule_uuid\n - **teachings (T):** instructor_id, section_uuid\n \n I.id --> T.instructor_id\n                \\/\n          T.section_uuid --> S.uuid\n                              \\/\n                             S.course_offering_uuid --> CO.uuid"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6d509f20-da02-4f50-aa2a-7832839dd7bb","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["teachings.show(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b3bb7eb0-0b0b-4f4a-a977-fa69cc27eefc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+--------------------+\n|instructor_id|        section_uuid|\n+-------------+--------------------+\n|       761703|45adf63c-48c9-365...|\n|       761703|c6280e23-5e43-385...|\n|       761703|9395dc21-15d1-3fa...|\n+-------------+--------------------+\nonly showing top 3 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Let's try to see all course offerings and who teaches it\n# Notice here that the variable we want to join on is different in the two datasets. \n# PySpark makes it easy to account for that\nstep1 = teachings.join(instructors, teachings.instructor_id == instructors.id, how='left').select(['instructor_id','name','section_uuid'])\nstep1.limit(4).toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"11ac8c67-3d32-4dc3-8fd1-2eccd56f3f8b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instructor_id</th>\n      <th>name</th>\n      <th>section_uuid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>761703</td>\n      <td>JOHN ARCHAMBAULT</td>\n      <td>45adf63c-48c9-3659-8561-07556d2d4ddf</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>761703</td>\n      <td>JOHN ARCHAMBAULT</td>\n      <td>c6280e23-5e43-3859-893e-540d94993529</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>761703</td>\n      <td>JOHN ARCHAMBAULT</td>\n      <td>9395dc21-15d1-3fab-8d1f-6f3fe6114c48</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3677061</td>\n      <td>STEPHANIE KANN</td>\n      <td>b99e440b-39db-350a-81eb-b6eb1bd8b0bc</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instructor_id</th>\n      <th>name</th>\n      <th>section_uuid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>761703</td>\n      <td>JOHN ARCHAMBAULT</td>\n      <td>45adf63c-48c9-3659-8561-07556d2d4ddf</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>761703</td>\n      <td>JOHN ARCHAMBAULT</td>\n      <td>c6280e23-5e43-3859-893e-540d94993529</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>761703</td>\n      <td>JOHN ARCHAMBAULT</td>\n      <td>9395dc21-15d1-3fab-8d1f-6f3fe6114c48</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3677061</td>\n      <td>STEPHANIE KANN</td>\n      <td>b99e440b-39db-350a-81eb-b6eb1bd8b0bc</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["step2 = step1.join(sections, step1.section_uuid == sections.uuid, how='left').select(['name','course_offering_uuid'])\nstep2.limit(4).toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9e07dede-d42a-4bed-8fbe-e358551ee69f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>course_offering_uuid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JAMES STEELE</td>\n      <td>dfac15fb-e446-339e-9403-38b270895b6c</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TERESA CLARK</td>\n      <td>878d4f26-4e7e-3cec-b2e3-28fd56d6489c</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JAMES STEELE</td>\n      <td>3fc6bfe1-7929-3f2e-af13-5185f1cf7383</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>STEPHANIE KANN</td>\n      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>course_offering_uuid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JAMES STEELE</td>\n      <td>dfac15fb-e446-339e-9403-38b270895b6c</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TERESA CLARK</td>\n      <td>878d4f26-4e7e-3cec-b2e3-28fd56d6489c</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JAMES STEELE</td>\n      <td>3fc6bfe1-7929-3f2e-af13-5185f1cf7383</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>STEPHANIE KANN</td>\n      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["step3 = step2.withColumnRenamed('name', 'instructor').join(course_offerings, step2.course_offering_uuid == course_offerings.uuid, how='inner').select(['instructor','name','course_offering_uuid'])\nstep3.limit(4).toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0185fbb9-e11b-4152-aba3-be0a48f903b6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instructor</th>\n      <th>name</th>\n      <th>course_offering_uuid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KAREN MC SHANE-HELLENBRAND</td>\n      <td>Modern Dance I</td>\n      <td>96f56d84-8c29-3dd5-8cf0-48608af3cbd2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MICHAEL FRANKLIN LORENZ</td>\n      <td>University Band</td>\n      <td>e32df8d0-c2ee-3d6c-acab-1c8b54f8506a</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BEVERLY TAYLOR</td>\n      <td>Choral Union</td>\n      <td>039866e7-d700-3146-82ab-57b7a92813a7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MARTIN PICKENS</td>\n      <td>Intro to Speech Composition</td>\n      <td>41e6b821-0d66-3ecc-925c-ffb16de7ab1d</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instructor</th>\n      <th>name</th>\n      <th>course_offering_uuid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KAREN MC SHANE-HELLENBRAND</td>\n      <td>Modern Dance I</td>\n      <td>96f56d84-8c29-3dd5-8cf0-48608af3cbd2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MICHAEL FRANKLIN LORENZ</td>\n      <td>University Band</td>\n      <td>e32df8d0-c2ee-3d6c-acab-1c8b54f8506a</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BEVERLY TAYLOR</td>\n      <td>Choral Union</td>\n      <td>039866e7-d700-3146-82ab-57b7a92813a7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MARTIN PICKENS</td>\n      <td>Intro to Speech Composition</td>\n      <td>41e6b821-0d66-3ecc-925c-ffb16de7ab1d</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## One final really cool way to join datasets: The Levenshtien distance!\n\nWhich basically counts the number of edits we would need to make too strings equal to eachother."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"594a9f2e-0c16-4f28-803b-d9ba9ef6396d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Compute the levenshtein distance beween two strings\n# pyspark.sql.functions.levenshtein(left, right)  \n\nfrom pyspark.sql.functions import levenshtein\n\ndf0 = spark.createDataFrame([('Aple', 'Apple','Microsoft','IBM')], ['Input', 'Option1','Option2','Option3'])\nprint(\"Correct this company name: Aple\")\ndf0.select(levenshtein('Input', 'Option1').alias('Apple')).show()\ndf0.select(levenshtein('Input', 'Option2').alias('Microsoft')).show()\ndf0.select(levenshtein('Input', 'Option3').alias('IBM')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5b785ca5-96b2-4eed-9500-449d21c60a34","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Correct this company name: Aple\n+-----+\n|Apple|\n+-----+\n|    1|\n+-----+\n\n+---------+\n|Microsoft|\n+---------+\n|        9|\n+---------+\n\n+---+\n|IBM|\n+---+\n|  4|\n+---+\n\n"]}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.10.6","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"Joining and Appending DataFrames in PySpark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":246377988539316}},"nbformat":4,"nbformat_minor":0}
